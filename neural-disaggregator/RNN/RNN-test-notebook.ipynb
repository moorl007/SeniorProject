{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Notebook to work on configurations without needing to train/test every time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to train the RNNDisaggregator using the train data. For this example, both train and test data are consumption data of the microwave of the first REDD building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "from nilmtk import DataSet\n",
    "\n",
    "train = DataSet('C:/Users/zebzi/Documents/School/Senior_Year/EE_4951W/SeniorProject/SeniorDataset/h5_files/RNN_test.h5')\n",
    "# except:\n",
    "#     train = DataSet('/SeniorDataset/h5_files/Zeb_test.h5')\n",
    "    \n",
    "train.set_window(start=\"1-1-2022\", end=\"2-1-2022\")\n",
    "train_elec = train.buildings[1].elec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define the disaggregator model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from rnndisaggregator import RNNDisaggregator\n",
    "rnn = RNNDisaggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then train the model. We need to input the train data as well as their sample period. Also, we need to pass the desired number of training epochs. Finally, save the model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeterGroup(meters=\n",
      "  ElecMeter(instance=1, building=1, dataset='Senior Design Dataset', site_meter, appliances=[])\n",
      "  ElecMeter(instance=2, building=1, dataset='Senior Design Dataset', appliances=[Appliance(type='fridge', instance=1)])\n",
      "  ElecMeter(instance=3, building=1, dataset='Senior Design Dataset', appliances=[Appliance(type='kettle', instance=1)])\n",
      "  ElecMeter(instance=4, building=1, dataset='Senior Design Dataset', appliances=[Appliance(type='computer', instance=1)])\n",
      "  ElecMeter(instance=5, building=1, dataset='Senior Design Dataset', appliances=[Appliance(type='microwave', instance=1)])\n",
      "  ElecMeter(instance=6, building=1, dataset='Senior Design Dataset', appliances=[Appliance(type='toaster', instance=1)])\n",
      "  ElecMeter(instance=7, building=1, dataset='Senior Design Dataset', appliances=[Appliance(type='hair dryer', instance=1)])\n",
      ")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m train_mains \u001b[39m=\u001b[39m train_elec\u001b[39m.\u001b[39mmains()\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(train_elec)\n\u001b[1;32m----> 9\u001b[0m rnn\u001b[39m.\u001b[39;49mtrain(train_mains, train_meter, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, sample_period\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     10\u001b[0m rnn\u001b[39m.\u001b[39mexport_model(\u001b[39m\"\u001b[39m\u001b[39mmodel-Zeb_test.h5\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zebzi\\Documents\\School\\Senior_Year\\EE_4951W\\SeniorProject\\neural-disaggregator\\RNN\\rnndisaggregator.py:68\u001b[0m, in \u001b[0;36mRNNDisaggregator.train\u001b[1;34m(self, mains, meter, epochs, batch_size, **load_kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m mainchunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_normalize(mainchunk, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmmax)\n\u001b[0;32m     66\u001b[0m meterchunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_normalize(meterchunk, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmmax)\n\u001b[1;32m---> 68\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_on_chunk(mainchunk, meterchunk, epochs, batch_size)\n\u001b[0;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     mainchunk \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(main_power_series)\n",
      "File \u001b[1;32mc:\\Users\\zebzi\\Documents\\School\\Senior_Year\\EE_4951W\\SeniorProject\\neural-disaggregator\\RNN\\rnndisaggregator.py:95\u001b[0m, in \u001b[0;36mRNNDisaggregator.train_on_chunk\u001b[1;34m(self, mainchunk, meterchunk, epochs, batch_size)\u001b[0m\n\u001b[0;32m     91\u001b[0m meterchunk \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(meterchunk[ix])\n\u001b[0;32m     93\u001b[0m mainchunk \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(mainchunk, (mainchunk\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[1;32m---> 95\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(mainchunk, meterchunk, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\zebzi\\anaconda3\\envs\\nilmWork\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\zebzi\\anaconda3\\envs\\nilmWork\\lib\\site-packages\\keras\\engine\\training.py:1576\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1574\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1575\u001b[0m \u001b[39mif\u001b[39;00m logs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnexpected result of `train_function` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1578\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(Empty logs). Please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1580\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1581\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minformation of where went wrong, or file a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1582\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39missue/bug to `tf.keras`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1583\u001b[0m     )\n\u001b[0;32m   1584\u001b[0m epoch_logs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mcopy(logs)\n\u001b[0;32m   1586\u001b[0m \u001b[39m# Run validation.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "meter_key = 'kettle'\n",
    "# train_mains = train_elec.mains().all_meters()[0] # The aggregated meter that provides the input\n",
    "# train_meter = train_elec.submeters()['microwave'] # The microwave meter that is used as a training target\n",
    "\n",
    "train_meter = train_elec.submeters()[meter_key]\n",
    "train_mains = train_elec.mains()\n",
    "print(train_elec)\n",
    "\n",
    "rnn.train(train_mains, train_meter, epochs=1, sample_period=1)\n",
    "rnn.export_model(\"model-Zeb_test.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can use it to disaggregate energy data. Let's test it on the rest of the data from building 1.\n",
    "\n",
    "First we use the model to predict the microwave consumption. The results are saved automatically in a .h5 datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the <test> dataset and set the test_mains variable\n",
    "try:\n",
    "    test = DataSet('ukdale.h5')\n",
    "except:\n",
    "    test = DataSet('/SeniorProject/neural-disaggregator/RNN/ukdale.h5')\n",
    "\n",
    "test.set_window(start=\"1-1-2014\", end=\"2-1-2014\")\n",
    "print(test.buildings[1].elec)\n",
    "test_elec = test.buildings[1].elec\n",
    "# test_mains = test_elec.mains().all_meters()[0]\n",
    "test_mains = test_elec.mains()\n",
    "# print(test_mains)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disag_filename = 'disag-out.h5' # The filename of the resulting datastore\n",
    "from nilmtk.datastore import HDFDataStore\n",
    "output = HDFDataStore(disag_filename, 'w')\n",
    "\n",
    "# test_mains: The aggregated signal meter\n",
    "# output: The output datastore\n",
    "# train_meter: This is used in order to copy the metadata of the train meter into the datastore\n",
    "rnn.disaggregate(test_mains, output, train_meter, sample_period=1)\n",
    "output.close()\n",
    "# output = HDFDataStore(disag_filename, 'r') why is this code here?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the results and compare them to the ground truth signal.\n",
    "\n",
    "**Note:** Calling plot this way, downsamples the signal to reduce computing time. To plot the entire signal call\n",
    "```\n",
    "predicted.power_series_all_data().plot()\n",
    "ground_truth.power_series_all_data().plot()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = DataSet(disag_filename)\n",
    "res_elec = result.buildings[1].elec\n",
    "predicted = res_elec['kettle']\n",
    "ground_truth = test_elec['kettle']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "predicted.plot(plot_kwargs={'color':'red', 'label':'Predicted'})\n",
    "ground_truth.plot(plot_kwargs={'color':'green', 'label':'Ground Truth'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's see the metric results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metrics\n",
    "rpaf = metrics.recall_precision_accuracy_f1(predicted, ground_truth)\n",
    "print(\"============ Recall: {}\".format(rpaf[0]))\n",
    "print(\"============ Precision: {}\".format(rpaf[1]))\n",
    "print(\"============ Accuracy: {}\".format(rpaf[2]))\n",
    "print(\"============ F1 Score: {}\".format(rpaf[3]))\n",
    "\n",
    "print(\"============ Relative error in total energy: {}\".format(metrics.relative_error_total_energy(predicted, ground_truth)))\n",
    "print(\"============ Mean absolute error(in Watts): {}\".format(metrics.mean_absolute_error(predicted, ground_truth)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nilmWork')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "090649b4642754db491605a7822e0ee72996d5555d9c4842996866e4da46c183"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
