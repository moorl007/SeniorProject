{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the RNN Disaggregator with NILMTK\n",
    "\n",
    "This is an example on how to train and use the Recurrent Network (RNN) disaggregator on the [REDD](http://redd.csail.mit.edu/) dataset using [NILMTK](https://github.com/nilmtk/NILMTK/).\n",
    "\n",
    "This network was described in the [Neural NILM](https://arxiv.org/pdf/1507.06594.pdf) paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to train the RNNDisaggregator using the train data. For this example, both train and test data are consumption data of the microwave of the first REDD building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file as /h5_files/96Hour.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m; warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnilmtk\u001b[39;00m \u001b[39mimport\u001b[39;00m DataSet\n\u001b[1;32m----> 4\u001b[0m train \u001b[39m=\u001b[39m DataSet(\u001b[39m'\u001b[39;49m\u001b[39m/h5_files/96Hour.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m train\u001b[39m.\u001b[39mset_window(start\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m2022-01-00T00\u001b[39m\u001b[39m'\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m2022-01-05T00\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m train_elec \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39mbuildings[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39melec\n",
      "File \u001b[1;32mc:\\Users\\zebzi\\anaconda3\\envs\\nilmWork\\lib\\site-packages\\nilmtk\\dataset.py:45\u001b[0m, in \u001b[0;36mDataSet.__init__\u001b[1;34m(self, filename, format)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata \u001b[39m=\u001b[39m {}\n\u001b[0;32m     44\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimport_metadata(get_datastore(filename, \u001b[39mformat\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\zebzi\\anaconda3\\envs\\nilmWork\\lib\\site-packages\\nilmtk\\utils.py:323\u001b[0m, in \u001b[0;36mget_datastore\u001b[1;34m(filename, format, mode)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    322\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHDF\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 323\u001b[0m         \u001b[39mreturn\u001b[39;00m HDFDataStore(filename, mode)\n\u001b[0;32m    324\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    325\u001b[0m         \u001b[39mreturn\u001b[39;00m CSVDataStore(filename)\n",
      "File \u001b[1;32mc:\\Users\\zebzi\\anaconda3\\envs\\nilmWork\\lib\\site-packages\\nilmtk\\docinherit.py:53\u001b[0m, in \u001b[0;36mDocInherit.__get__.<locals>.f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39m@wraps\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmthd, assigned\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m__module__\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m obj:\n\u001b[1;32m---> 53\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmthd(obj, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     54\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmthd(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zebzi\\anaconda3\\envs\\nilmWork\\lib\\site-packages\\nilmtk\\datastore\\hdfdatastore.py:18\u001b[0m, in \u001b[0;36mHDFDataStore.__init__\u001b[1;34m(self, filename, mode)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m@doc_inherit\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, filename, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     17\u001b[0m     \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m [ \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m ] \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m isfile(filename):\n\u001b[1;32m---> 18\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo such file as \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m filename)\n\u001b[0;32m     20\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[0;32m     21\u001b[0m         \u001b[39m# Silence pytables warnings with numpy, out of our control\u001b[39;00m\n\u001b[0;32m     22\u001b[0m         warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m, category\u001b[39m=\u001b[39m\u001b[39mRuntimeWarning\u001b[39;00m, message\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.*numpy.ufunc size changed.*\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: No such file as /h5_files/96Hour.h5"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "from nilmtk import DataSet\n",
    "train = DataSet('../../SeniorDataset/h5_files/96Hour.h5')\n",
    "train.set_window(start='2022-01-00T00', end='2022-01-05T00')\n",
    "train_elec = train.buildings[1].elec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define the disaggregator model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnndisaggregator import RNNDisaggregator\n",
    "rnn = RNNDisaggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then train the model. We need to input the train data as well as their sample period. Also, we need to pass the desired number of training epochs. Finally, save the model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mains = train_elec.mains() # The aggregated meter that provides the input\n",
    "print(train_mains)\n",
    "train_meter = train_elec.submeters()['kettle'] # The microwave meter that is used as a training target\n",
    "\n",
    "rnn.train(train_mains, train_meter, epochs=1, sample_period=1)\n",
    "rnn.export_model(\"model-ukDaleTEST.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can use it to disaggregate energy data. Let's test it on the rest of the data from building 1.\n",
    "\n",
    "First we use the model to predict the microwave consumption. The results are saved automatically in a .h5 datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = DataSet('ukdale.h5')\n",
    "test.set_window(start=\"1-3-2014\", end=\"1-4-2014\")\n",
    "test_elec = test.buildings[1].elec\n",
    "test_mains = test_elec.mains()\n",
    "\n",
    "disag_filename = 'disag-outUKDALE_TEST.h5' # The filename of the resulting datastore\n",
    "from nilmtk.datastore import HDFDataStore\n",
    "output = HDFDataStore(disag_filename, 'w')\n",
    "\n",
    "# test_mains: The aggregated signal meter\n",
    "# output: The output datastore\n",
    "# train_meter: This is used in order to copy the metadata of the train meter into the datastore\n",
    "rnn.disaggregate(test_mains, output, train_meter, sample_period=1)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the results and compare them to the ground truth signal.\n",
    "\n",
    "**Note:** Calling plot this way, downsamples the signal to reduce computing time. To plot the entire signal call\n",
    "```\n",
    "predicted.power_series_all_data().plot()\n",
    "ground_truth.power_series_all_data().plot()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = DataSet(disag_filename)\n",
    "res_elec = result.buildings[1].elec\n",
    "predicted = res_elec['kettle']\n",
    "ground_truth = test_elec['kettle']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "predicted.plot(plot_kwargs={'color':'red', 'label':'Predicted'})\n",
    "ground_truth.plot(plot_kwargs={'color':'green', 'label':'Ground Truth'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's see the metric results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metrics\n",
    "rpaf = metrics.recall_precision_accuracy_f1(predicted, ground_truth)\n",
    "print(\"============ Recall: {}\".format(rpaf[0]))\n",
    "print(\"============ Precision: {}\".format(rpaf[1]))\n",
    "print(\"============ Accuracy: {}\".format(rpaf[2]))\n",
    "print(\"============ F1 Score: {}\".format(rpaf[3]))\n",
    "\n",
    "print(\"============ Relative error in total energy: {}\".format(metrics.relative_error_total_energy(predicted, ground_truth)))\n",
    "print(\"============ Mean absolute error(in Watts): {}\".format(metrics.mean_absolute_error(predicted, ground_truth)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nilmWork')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "090649b4642754db491605a7822e0ee72996d5555d9c4842996866e4da46c183"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
